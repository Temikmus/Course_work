import re
from fastapi import APIRouter, Depends, Query, HTTPException
from sqlalchemy.orm import Session
from sqlalchemy import func, and_, or_, cast, case
from database import SessionLocal
from datetime import datetime
from sqlalchemy.dialects.postgresql import ARRAY, VARCHAR
from sqlalchemy.types import String, DateTime, Date, ARRAY
from sqlalchemy.sql.functions import percentile_cont
from sqlalchemy.sql.expression import select
import logging


# Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ ÑÑ‚Ð¾Ð»Ð±Ñ†Ð¾Ð² Ð² Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ (ÑÑ‚Ð¾Ð»Ð±Ñ†Ñ‹, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ð±ÑƒÐ´ÑƒÑ‚ Ð² Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ðµ Ð¿Ñ€Ð¸ Ð²Ñ‹Ð²Ð¾Ð´Ðµ)
def add_columns_to_result(query, fields, base_model):
    selected_columns = []
    for field in fields:
        if hasattr(base_model, field):
            selected_columns.append(getattr(base_model, field))
        else:
            raise HTTPException(status_code=400, detail=f"ÐŸÐ¾Ð»Ðµ '{field}' Ð½Ðµ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÐµÑ‚")
    if selected_columns:
        query = query.with_entities(*selected_columns)
    return query

# ÐŸÐ°Ñ€ÑÐ¸Ñ‚ ÑÑ‚Ñ€Ð¾ÐºÑƒ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð¾Ð²
def parse_filters(filters):
    """

    :param filters: "salary_to>=and:50000~60000~70000;min_experience<or:3~5~7;title=or:Data~Analyst~Scientist"
    :return:
    {
    'salary_to': ('>=', ['50000', '60000', '70000'], 'and'),
    'min_experience': ('<', ['3', '5', '7'], 'or'),
    'title': ('=', ['Data', 'Analyst', 'Scientist'], 'or')
    }

    """
    result = {}
    if not filters:
        return result  # Ð•ÑÐ»Ð¸ Ð¿ÑƒÑÑ‚Ð°Ñ ÑÑ‚Ñ€Ð¾ÐºÐ°, Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÐ¼ Ð¿ÑƒÑÑ‚Ð¾Ð¹ ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ
    try:
        # Ð Ð°Ð·Ð±Ð¸Ð²Ð°ÐµÐ¼ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ñ‹ Ð¿Ð¾ `;`, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ñ€Ð°Ð·Ð´ÐµÐ»Ð¸Ñ‚ÑŒ Ñ€Ð°Ð·Ð½Ñ‹Ðµ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ñ‹
        filter_parts = filters.split(";")

        # Ð ÐµÐ³ÑƒÐ»ÑÑ€ÐºÐ° Ð´Ð»Ñ Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³Ð° "ÑÑ‚Ð¾Ð»Ð±ÐµÑ† Ð¾Ð¿ÐµÑ€Ð°Ñ‚Ð¾Ñ€ Ð¸ Ð¿Ñ€ÐµÑ„Ð¸ÐºÑ (and|or) Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ"
        pattern = re.compile(r"^\s*([^=!<>]+)\s*([=!<>]+)\s*(and:|or:)?(.*)$")

        for part in filter_parts:
            match = pattern.match(part)
            if not match:
                continue  # Ð•ÑÐ»Ð¸ Ñ‡Ð°ÑÑ‚ÑŒ Ð½Ðµ ÑÐ¾Ð²Ð¿Ð°Ð»Ð° Ñ ÑˆÐ°Ð±Ð»Ð¾Ð½Ð¾Ð¼, Ð¿Ñ€Ð¾Ð¿ÑƒÑÐºÐ°ÐµÐ¼

            column, operator, logical_prefix, values_str = match.groups()
            column, operator = column.strip(), operator.strip()
            values_str = values_str.strip()

            # Ð•ÑÐ»Ð¸ ÐµÑÑ‚ÑŒ Ð¿Ñ€ÐµÑ„Ð¸ÐºÑ (and: Ð¸Ð»Ð¸ or:), Ñ‚Ð¾ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ ÐµÐ³Ð¾ Ð´Ð»Ñ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ñ Ð»Ð¾Ð³Ð¸Ñ‡ÐµÑÐºÐ¾Ð³Ð¾ Ð¾Ð¿ÐµÑ€Ð°Ñ‚Ð¾Ñ€Ð°
            if logical_prefix:
                separator = logical_prefix[:-1]  # Ð£Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ð´Ð²Ð¾ÐµÑ‚Ð¾Ñ‡Ð¸Ðµ (and: Ð¸Ð»Ð¸ or:)
                values = values_str.split("~")  # Ð Ð°Ð·Ð´ÐµÐ»ÑÐµÐ¼ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ Ð²Ð½ÑƒÑ‚Ñ€Ð¸ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð° Ð¿Ð¾ "~"
                result[column] = (operator, [v.strip() for v in values], separator)
            else:
                # Ð Ð°Ð·Ð´ÐµÐ»ÑÐµÐ¼ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ Ð²Ð½ÑƒÑ‚Ñ€Ð¸ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð° Ð¿Ð¾ "~"
                values = values_str.split("~")
                separator = "and"  # ÐŸÐ¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ Ð»Ð¾Ð³Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð¾Ð¿ÐµÑ€Ð°Ñ‚Ð¾Ñ€ "and"
                result[column] = (operator, [v.strip() for v in values], separator)

        return result
    except Exception as e:
        logging.error(f"Error parse: '{e}")
        raise


# ÐŸÑ€Ð¸Ð¼ÐµÐ½ÑÐµÐ¼ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€ Ð´Ð»Ñ ÑÑ‚Ð¾Ð»Ð±Ñ†Ð° Ñ‚Ð¸Ð¿Ð° array, Ñ‚Ð°Ðº ÐºÐ°Ðº Ñ‚Ð°Ð¼ Ð¸Ð´ÐµÑ‚ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð´Ð»Ñ ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚Ð° Ð¼Ð°ÑÑÐ¸Ð²Ð°:
# ÐµÑÐ»Ð¸ Ð´Ð»Ñ ÐºÐ°ÐºÐ¾Ð³Ð¾-Ñ‚Ð¾ ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚Ð° Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÑÐµÑ‚ÑÑ ÑƒÑÐ»Ð¾Ð²Ð¸Ðµ, Ñ‚Ð¾ ÑÑ‚Ð° ÑÑ‚Ñ€Ð¾ÐºÐ° Ð´Ð¾Ð±Ð°Ð²Ð»ÑÐµÑ‚ÑÑ Ðº Ð²Ñ‹Ð²Ð¾Ð´Ñƒ
# (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€, skills=sql Ð²Ñ‹Ð²ÐµÐ´ÐµÑ‚ Ð²ÑÐµ ÑÑ‚Ñ€Ð¾ÐºÐ¸, Ð³Ð´Ðµ ÐµÑÑ‚ÑŒ Ð² skills sql)
def apply_compare_filter_for_array_column(query: Query, column: str, values, operator: str, separator: str, base_model):
    column_attr = getattr(base_model, column, None)
    if not column_attr:
        raise ValueError(f"Ð¡Ñ‚Ð¾Ð»Ð±ÐµÑ† '{column}' Ð½Ðµ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÐµÑ‚ Ð² Ð¼Ð¾Ð´ÐµÐ»Ð¸ Vacancy")
    try:
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ñ‚Ð¸Ð¿ ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚Ð° Ð¼Ð°ÑÑÐ¸Ð²Ð°
        item_type = column_attr.type.item_type
        print(f"Type of column: {type(item_type)}")  # ÐŸÐµÑ‡Ð°Ñ‚Ð°ÐµÐ¼ Ñ‚Ð¸Ð¿ ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚Ð° Ð¼Ð°ÑÑÐ¸Ð²Ð°

        # Ð•ÑÐ»Ð¸ Ñ‚Ð¸Ð¿ ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚Ð° Ð¼Ð°ÑÑÐ¸Ð²Ð° â€” String (VARCHAR Ð¸Ð»Ð¸ TEXT)
        if isinstance(item_type, String):
            # ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ Ð¾Ð¿ÐµÑ€Ð°Ñ‚Ð¾Ñ€Ñ‹ Ð´Ð»Ñ ÑÑ‚Ñ€Ð¾ÐºÐ¾Ð²Ñ‹Ñ… ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚Ð¾Ð² Ð² Ð¼Ð°ÑÑÐ¸Ð²Ðµ
            operators = {
                "=": lambda value: column_attr.any(value),  # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð½Ð°Ð»Ð¸Ñ‡Ð¸Ðµ ÑÑ‚Ñ€Ð¾ÐºÐ¸ Ð² Ð¼Ð°ÑÑÐ¸Ð²Ðµ
                "!=": lambda value: ~column_attr.any(value),  # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ð²Ð¸Ðµ ÑÑ‚Ñ€Ð¾ÐºÐ¸ Ð² Ð¼Ð°ÑÑÐ¸Ð²Ðµ
                "==": lambda value: func.array_to_string(column_attr, ',').ilike(f"%{value}%")  # ÐÐµÑ‡ÑƒÐ²ÑÑ‚Ð²Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ðµ ÑÑ€Ð°Ð²Ð½ÐµÐ½Ð¸Ðµ Ð¿Ð¾Ð´ÑÑ‚Ñ€Ð¾ÐºÐ¸
            }
        else:
            print("Not a String array")
            # ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ Ð¾Ð±Ñ‹Ñ‡Ð½Ñ‹Ðµ Ð¾Ð¿ÐµÑ€Ð°Ñ‚Ð¾Ñ€Ñ‹ Ð´Ð»Ñ Ð´Ñ€ÑƒÐ³Ð¸Ñ… Ñ‚Ð¸Ð¿Ð¾Ð²
            operators = {
                "=": lambda value: column_attr.any(value),  # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð½Ð°Ð»Ð¸Ñ‡Ð¸Ðµ ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚Ð° Ð² Ð¼Ð°ÑÑÐ¸Ð²Ðµ
                "!=": lambda value: ~column_attr.any(value)  # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ð²Ð¸Ðµ ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚Ð° Ð² Ð¼Ð°ÑÑÐ¸Ð²Ðµ
            }

        if operator not in operators:
            raise ValueError(f"ÐžÐ¿ÐµÑ€Ð°Ñ‚Ð¾Ñ€ '{operator}' Ð½Ðµ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÑ‚ÑÑ Ð´Ð»Ñ Ð¼Ð°ÑÑÐ¸Ð²Ð°")

        # ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·ÑƒÐµÐ¼ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ Ð² ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ðµ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ñ‹
        conditions = [operators[operator](value) for value in values]

        # Ð›Ð¾Ð³Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ Ð¾Ð±ÑŠÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ðµ (OR Ð¸Ð»Ð¸ AND)
        if separator == "or":
            condition = or_(*conditions)  # OR
        else:
            condition = and_(*conditions)  # AND

        return query.filter(condition)
    except Exception as e:
        logging.error(f"Error array_column: '{e}")
        raise

#ÐŸÑ€Ð¸Ð¼ÐµÐ½ÑÐµÐ¼ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€ Ð´Ð»Ñ ÑÑ‚Ð¾Ð»Ð±Ñ†Ð° Ñ Ð¾Ð´Ð½Ð¸Ð¼ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸ÐµÐ¼
def apply_compare_filter_for_column_with_one_value(query: Query, column: str, values, operator: str, separator: str, base_model):
    column_attr = getattr(base_model, column, None)
    if not column_attr:
        raise ValueError(f"Ð¡Ñ‚Ð¾Ð»Ð±ÐµÑ† '{column}' Ð½Ðµ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÐµÑ‚ Ð² Ð¼Ð¾Ð´ÐµÐ»Ð¸ Vacancy")
    try:
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ñ‚Ð¸Ð¿Ð° ÑÑ‚Ð¾Ð»Ð±Ñ†Ð°
        item_type = column_attr.type
        if isinstance(item_type, String):
            # Ð”Ð»Ñ ÑÑ‚Ñ€Ð¾Ðº Ð´Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð¾Ð¿ÐµÑ€Ð°Ñ‚Ð¾Ñ€ Ð´Ð»Ñ Ð½ÐµÑ‡ÑƒÐ²ÑÑ‚Ð²Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð³Ð¾ ÑÑ€Ð°Ð²Ð½ÐµÐ½Ð¸Ñ Ð¿Ð¾Ð´ÑÑ‚Ñ€Ð¾ÐºÐ¸
            operators = {
                ">": lambda value: column_attr > value,
                ">=": lambda value: column_attr >= value,
                "<": lambda value: column_attr < value,
                "<=": lambda value: column_attr <= value,
                "=": lambda value: column_attr == value,
                "!=": lambda value: column_attr != value,
                "==": lambda value: column_attr.ilike(f"%{value}%"),  # ÐÐµÑ‡ÑƒÐ²ÑÑ‚Ð²Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ðµ ÑÑ€Ð°Ð²Ð½ÐµÐ½Ð¸Ðµ Ð¿Ð¾Ð´ÑÑ‚Ñ€Ð¾ÐºÐ¸
            }
        elif isinstance(item_type, DateTime):
            # Ð”Ð»Ñ ÑÑ‚Ð¾Ð»Ð±Ñ†Ð¾Ð² Ñ‚Ð¸Ð¿Ð° DateTime Ð¿Ñ€ÐµÐ¾Ð±Ñ€Ð°Ð·ÑƒÐµÐ¼ ÑÑ‚Ñ€Ð¾ÐºÑƒ Ð² datetime Ð¸ ÑÑ€Ð°Ð²Ð½Ð¸Ð²Ð°ÐµÐ¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð´Ð°Ñ‚Ñƒ
            operators = {
                ">": lambda value: cast(column_attr, Date) > datetime.strptime(value, "%Y-%m-%d").date(),
                ">=": lambda value: cast(column_attr, Date) >= datetime.strptime(value, "%Y-%m-%d").date(),
                "<": lambda value: cast(column_attr, Date) < datetime.strptime(value, "%Y-%m-%d").date(),
                "<=": lambda value: cast(column_attr, Date) <= datetime.strptime(value, "%Y-%m-%d").date(),
                "=": lambda value: cast(column_attr, Date) == datetime.strptime(value, "%Y-%m-%d").date(),
                "!=": lambda value: cast(column_attr, Date) != datetime.strptime(value, "%Y-%m-%d").date(),
            }
        else:
            # Ð”Ð»Ñ Ð´Ñ€ÑƒÐ³Ð¸Ñ… Ñ‚Ð¸Ð¿Ð¾Ð² ÑÑ‚Ð¾Ð»Ð±Ñ†Ð¾Ð²
            operators = {
                ">": lambda value: column_attr > value,
                ">=": lambda value: column_attr >= value,
                "<": lambda value: column_attr < value,
                "<=": lambda value: column_attr <= value,
                "=": lambda value: column_attr == value,
                "!=": lambda value: column_attr != value,
            }

        if operator not in operators:
            raise ValueError(f"ÐžÐ¿ÐµÑ€Ð°Ñ‚Ð¾Ñ€ '{operator}' Ð½Ðµ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÑ‚ÑÑ")

        # ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·ÑƒÐµÐ¼ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ Ð² ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ðµ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ñ‹
        conditions = [operators[operator](value) for value in values]

        # Ð›Ð¾Ð³Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ Ð¾Ð±ÑŠÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ðµ (OR Ð¸Ð»Ð¸ AND)
        if separator == "or":
            condition = or_(*conditions)  # OR
        else:
            condition = and_(*conditions)  # AND

        return query.filter(condition)
    except Exception as e:
        logging.error(f"One value: '{e}")
        raise


def apply_filter_for_column(query: Query, column: str, values, operator: str, separator: str, base_model):
    column_model = getattr(base_model, column)
    # Ð•ÑÐ»Ð¸ Ð¿Ð¾Ð»Ðµ ÑÐ²Ð»ÑÐµÑ‚ÑÑ Ð¼Ð°ÑÑÐ¸Ð²Ð¾Ð¼, Ð´Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ ÐµÐ³Ð¾ Ð² GROUP BY
    if isinstance(column_model.type, ARRAY):
        query = apply_compare_filter_for_array_column(query, column, values, operator, separator, base_model)
    else:
        query = apply_compare_filter_for_column_with_one_value(query, column, values, operator, separator, base_model)
    return query



# Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð² Ð¼Ð°ÑÑÐ¸Ð² ÑÑ‚Ð¾Ð±Ñ†Ñ‹, Ð¿Ð¾ ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¼ Ð±ÑƒÐ´ÐµÑ‚ Ð¿Ñ€Ð¾Ð¸Ð·Ð²ÐµÐ´ÐµÐ½Ð° Ð³Ñ€ÑƒÐ¿Ð¿Ð¸Ñ€Ð¾Ð²ÐºÐ°, Ð¿Ñ€Ð¸Ñ‡ÐµÐ¼
# ÐµÑÐ»Ð¸ ÑÑ‚Ð¾Ñ‚ ÑÑ‚Ð¾Ð»Ð±ÐµÑ† - Ð¼Ð°ÑÑÐ¸Ð², Ñ‚Ð¾ Ð¾Ð½ Ñ€Ð°Ð·Ð±Ð¸Ð²Ð°ÐµÑ‚ÑÑ Ð¿Ð¾ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸ÑÐ¼ Ð² Ð¼Ð°ÑÑÐ¸Ð²Ðµ (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€, Ð³Ñ€ÑƒÐ¿Ð¿Ð¸Ñ€Ð¾Ð²ÐºÐ° Ð¿Ð¾ skills:)
# Ð²Ñ‹Ð´Ð°ÑÑ‚ ÑÑ‚Ð¾Ð»Ð±ÐµÑ† Ð² ÐºÐ¾Ñ‚Ð¾Ñ€Ð¾Ð¼ Ð¿Ð¾ ÑÐºÐ¸Ð»Ð»Ð°Ð¼ Ð¸Ð´ÐµÑ‚ Ñ€Ð°Ð·Ð²ÐµÑ‚Ð²Ð»ÐµÐ½Ð¸Ðµ
def find_group_columns(group_by, base_model):
    group_columns = []
    if group_by:
        group_fields = group_by.split(",")
        for field in group_fields:
            column_attr = getattr(base_model, field, None)
            if not column_attr:
                raise HTTPException(status_code=400, detail=f"ÐŸÐ¾Ð»Ðµ '{field}' Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ Ð´Ð»Ñ Ð³Ñ€ÑƒÐ¿Ð¿Ð¸Ñ€Ð¾Ð²ÐºÐ¸")
            # ðŸ”¹ ÐžÑ‚Ð»Ð°Ð´Ð¾Ñ‡Ð½Ñ‹Ð¹ Ð²Ñ‹Ð²Ð¾Ð´
            print(f"ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ Ð¿Ð¾Ð»Ðµ {field}: {column_attr.type}")
            # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, ÑÐ²Ð»ÑÐµÑ‚ÑÑ Ð»Ð¸ Ð¿Ð¾Ð»Ðµ Ð¼Ð°ÑÑÐ¸Ð²Ð¾Ð¼
            if isinstance(column_attr.type, ARRAY):
                print(f"ðŸ”¹ ÐŸÐ¾Ð»Ðµ {field} ÑÐ²Ð»ÑÐµÑ‚ÑÑ Ð¼Ð°ÑÑÐ¸Ð²Ð¾Ð¼. ÐŸÑ€Ð¸Ð¼ÐµÐ½ÑÐµÐ¼ `unnest()`.")
                unnest_column = func.unnest(column_attr).label(field)
                group_columns.append(unnest_column)
            else:
                print(f"ðŸ”¸ ÐŸÐ¾Ð»Ðµ {field} ÐÐ• Ð¼Ð°ÑÑÐ¸Ð².")
                group_columns.append(column_attr)
    return group_columns



# Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ñ€Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð½Ñ‹Ð¹ ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ Ð°Ð³Ñ€ÐµÐ³Ð°Ñ‚Ð½Ñ‹Ñ… Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¹
aggregate_funcs = {
    "avg": func.avg,  # Ð¡Ñ€ÐµÐ´Ð½ÐµÐµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ
    "sum": func.sum,  # Ð¡ÑƒÐ¼Ð¼Ð°
    "max": func.max,  # ÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ
    "min": func.min,  # ÐœÐ¸Ð½Ð¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ
    "count": func.count,  # ÐŸÐ¾Ð´ÑÑ‡ÐµÑ‚ ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚Ð¾Ð²
    "median": lambda col: func.percentile_cont(0.5).within_group(col),  # ÐœÐµÐ´Ð¸Ð°Ð½Ð°
    "stddev": func.stddev,  # Ð¡Ñ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚Ð½Ð¾Ðµ Ð¾Ñ‚ÐºÐ»Ð¾Ð½ÐµÐ½Ð¸Ðµ
    "variance": func.variance,  # Ð”Ð¸ÑÐ¿ÐµÑ€ÑÐ¸Ñ
    "group_concat": func.string_agg,  # ÐšÐ¾Ð½ÐºÐ°Ñ‚ÐµÐ½Ð°Ñ†Ð¸Ñ ÑÑ‚Ñ€Ð¾Ðº
    "distinct_count": func.count(distinct=True),  # ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ ÑƒÐ½Ð¸ÐºÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ð¹
    "array_agg": func.array_agg,  # ÐÐ³Ñ€ÐµÐ³Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð² Ð¼Ð°ÑÑÐ¸Ð²
    "mode": lambda col: func.mode().within_group(col),  # ÐœÐ¾Ð´Ð°
    "first": func.first,  # ÐŸÐµÑ€Ð²Ñ‹Ð¹ ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚
    "last": func.last,  # ÐŸÐ¾ÑÐ»ÐµÐ´Ð½Ð¸Ð¹ ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚
    "sum_distinct": lambda col: func.sum(func.distinct(col)),  # Ð¡ÑƒÐ¼Ð¼Ð° ÑƒÐ½Ð¸ÐºÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ð¹
    "corr": func.corr,  # ÐšÐ¾ÑÑ„Ñ„Ð¸Ñ†Ð¸ÐµÐ½Ñ‚ ÐºÐ¾Ñ€Ñ€ÐµÐ»ÑÑ†Ð¸Ð¸ ÐŸÐ¸Ñ€ÑÐ¾Ð½Ð°
    "covar_pop": func.covar_pop,  # Ð¡Ð¾Ð²Ð¾ÐºÑƒÐ¿Ð½Ð°Ñ Ð´Ð¸ÑÐ¿ÐµÑ€ÑÐ¸Ñ
    "covar_samp": func.covar_samp,  # Ð’Ñ‹Ð±Ð¾Ñ€Ð¾Ñ‡Ð½Ð°Ñ Ð´Ð¸ÑÐ¿ÐµÑ€ÑÐ¸Ñ
    "regr_slope": func.regr_slope,  # ÐÐ°ÐºÐ»Ð¾Ð½ Ñ€ÐµÐ³Ñ€ÐµÑÑÐ¸Ð¾Ð½Ð½Ð¾Ð¹ Ð»Ð¸Ð½Ð¸Ð¸
    "regr_intercept": func.regr_intercept,  # ÐŸÐµÑ€ÐµÑ…Ð²Ð°Ñ‚ Ñ€ÐµÐ³Ñ€ÐµÑÑÐ¸Ð¾Ð½Ð½Ð¾Ð¹ Ð»Ð¸Ð½Ð¸Ð¸
    "regr_r2": func.regr_r2,  # ÐšÐ¾ÑÑ„Ñ„Ð¸Ñ†Ð¸ÐµÐ½Ñ‚ Ð´ÐµÑ‚ÐµÑ€Ð¼Ð¸Ð½Ð°Ñ†Ð¸Ð¸
    "rank": func.rank,  # Ð Ð°Ð½Ð³
    "dense_rank": func.dense_rank,  # ÐŸÐ»Ð¾Ñ‚Ð½Ñ‹Ð¹ Ñ€Ð°Ð½Ð³
    "row_number": func.row_number,  # ÐÐ¾Ð¼ÐµÑ€ ÑÑ‚Ñ€Ð¾ÐºÐ¸
    "ntile": func.ntile,  # Ð Ð°Ð·Ð±Ð¸ÐµÐ½Ð¸Ðµ Ð½Ð° N Ð³Ñ€ÑƒÐ¿Ð¿
    "json_agg": func.json_agg,  # ÐÐ³Ñ€ÐµÐ³Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð² JSON
    "jsonb_agg": func.jsonb_agg,  # ÐÐ³Ñ€ÐµÐ³Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð² JSONB (PostgreSQL)
    "json_build_object": func.json_build_object,  # ÐŸÐ¾ÑÑ‚Ñ€Ð¾ÐµÐ½Ð¸Ðµ JSON-Ð¾Ð±ÑŠÐµÐºÑ‚Ð°
    "jsonb_build_object": func.jsonb_build_object,  # ÐŸÐ¾ÑÑ‚Ñ€Ð¾ÐµÐ½Ð¸Ðµ JSONB-Ð¾Ð±ÑŠÐµÐºÑ‚Ð° (PostgreSQL)
    "array_length": func.array_length,  # Ð”Ð»Ð¸Ð½Ð° Ð¼Ð°ÑÑÐ¸Ð²Ð°
    "array_dims": func.array_dims,  # Ð Ð°Ð·Ð¼ÐµÑ€Ð½Ð¾ÑÑ‚ÑŒ Ð¼Ð°ÑÑÐ¸Ð²Ð°
    "string_agg": func.string_agg,  # ÐšÐ¾Ð½ÐºÐ°Ñ‚ÐµÐ½Ð°Ñ†Ð¸Ñ ÑÑ‚Ñ€Ð¾Ðº Ñ Ñ€Ð°Ð·Ð´ÐµÐ»Ð¸Ñ‚ÐµÐ»ÐµÐ¼
    "upper": func.upper,  # ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð² Ð²ÐµÑ€Ñ…Ð½Ð¸Ð¹ Ñ€ÐµÐ³Ð¸ÑÑ‚Ñ€
    "lower": func.lower,  # ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð² Ð½Ð¸Ð¶Ð½Ð¸Ð¹ Ñ€ÐµÐ³Ð¸ÑÑ‚Ñ€
    "trim": func.trim,  # Ð£Ð´Ð°Ð»ÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¾Ð±ÐµÐ»Ð¾Ð² Ñ Ð¾Ð±ÐµÐ¸Ñ… ÑÑ‚Ð¾Ñ€Ð¾Ð½
    "length": func.length,  # Ð”Ð»Ð¸Ð½Ð° ÑÑ‚Ñ€Ð¾ÐºÐ¸
    "concat": func.concat,  # ÐšÐ¾Ð½ÐºÐ°Ñ‚ÐµÐ½Ð°Ñ†Ð¸Ñ ÑÑ‚Ñ€Ð¾Ðº
    "now": func.now,  # Ð¢ÐµÐºÑƒÑ‰ÐµÐµ Ð²Ñ€ÐµÐ¼Ñ
    "current_timestamp": func.current_timestamp,  # Ð¢ÐµÐºÑƒÑ‰ÐµÐµ Ð²Ñ€ÐµÐ¼Ñ (timestamp)
    "date_trunc": func.date_trunc,  # ÐžÐºÑ€ÑƒÐ³Ð»ÐµÐ½Ð¸Ðµ Ð´Ð°Ñ‚Ñ‹
    "age": func.age,  # Ð Ð°Ð·Ð½Ð¸Ñ†Ð° Ð¼ÐµÐ¶Ð´Ñƒ Ð´Ð°Ñ‚Ð°Ð¼Ð¸ (Ð²Ð¾Ð·Ñ€Ð°ÑÑ‚)
    "extract": func.extract,  # Ð˜Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ðµ Ñ‡Ð°ÑÑ‚Ð¸ Ð´Ð°Ñ‚Ñ‹
    "date_part": func.date_part,  # Ð§Ð°ÑÑ‚Ð¸ Ð´Ð°Ñ‚Ñ‹
    "to_char": func.to_char,  # ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð² ÑÑ‚Ñ€Ð¾ÐºÑƒ (Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ Ð´Ð°Ñ‚Ñ‹/Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸)
    "date": func.date,  # ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð´Ð°Ñ‚Ñ‹ Ð² Ð´Ñ€ÑƒÐ³Ð¾Ð¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚
    "to_date": func.to_date,  # ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·Ð¾Ð²Ð°Ð½Ð¸Ðµ ÑÑ‚Ñ€Ð¾ÐºÐ¸ Ð² Ð´Ð°Ñ‚Ñƒ
    "to_timestamp": func.to_timestamp,  # ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·Ð¾Ð²Ð°Ð½Ð¸Ðµ ÑÑ‚Ñ€Ð¾ÐºÐ¸ Ð² timestamp
    "coalesce": func.coalesce,  # Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ð¿ÐµÑ€Ð²Ñ‹Ð¹ Ð½ÐµÐ½ÑƒÐ»ÐµÐ²Ð¾Ð¹ Ð°Ñ€Ð³ÑƒÐ¼ÐµÐ½Ñ‚
    "nullif": func.nullif,  # Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ null, ÐµÑÐ»Ð¸ Ð´Ð²Ð° Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ Ñ€Ð°Ð²Ð½Ñ‹
}

def find_aggregate_columns_for_group_by(aggregates, base_model):
    selected_aggregates = []
    if aggregates:
        agg_fields = aggregates.split(",")
        for agg in agg_fields:
            field, agg_type = agg.split(":")
            column_attr = getattr(base_model, field, None)
            if column_attr and agg_type in aggregate_funcs:
                selected_aggregates.append(aggregate_funcs[agg_type](column_attr).label(f"{field}_{agg_type}"))
            else:
                raise HTTPException(status_code=400, detail=f"ÐÐµÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ñ‹Ð¹ Ð°Ð³Ñ€ÐµÐ³Ð°Ñ‚ '{agg}'")
    return selected_aggregates

def apply_group_by(query, group_columns,selected_aggregates):
    # Ð•ÑÐ»Ð¸ ÐµÑÑ‚ÑŒ Ð³Ñ€ÑƒÐ¿Ð¿Ð¸Ñ€Ð¾Ð²ÐºÐ° Ð¸ Ð°Ð³Ñ€ÐµÐ³Ð°Ñ‚Ñ‹, Ð¾Ð±ÑŠÐµÐ´Ð¸Ð½ÑÐµÐ¼
    if group_columns and selected_aggregates:
        query = query.with_entities(*group_columns, *selected_aggregates).group_by(*group_columns)
    elif group_columns:
        query = query.with_entities(*group_columns).group_by(*group_columns)
    elif selected_aggregates:
        query = query.with_entities(*selected_aggregates)
    return query




def apply_sorting_of_table(query, group_columns, selected_aggregates, sort_by, base_model):
    try:
        if sort_by:
            sort_fields = sort_by.split(",")
            for sort in sort_fields:
                parts = sort.split(":")
                if len(parts) == 2:  # ÐžÐ±Ñ‹Ñ‡Ð½Ð°Ñ ÑÐ¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²ÐºÐ°
                    field, order = parts
                    if hasattr(base_model, field):
                        column = getattr(base_model, field)
                        if isinstance(column.type, ARRAY):
                            unnest_column = func.unnest(column).label(field)
                            group_columns.append(unnest_column)
                    else:
                        raise HTTPException(status_code=400, detail=f"ÐŸÐ¾Ð»Ðµ '{field}' Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ Ð´Ð»Ñ ÑÐ¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²ÐºÐ¸")
                elif len(parts) == 3:  # ÐÐ³Ñ€ÐµÐ³Ð°Ñ‚Ð½Ð°Ñ ÑÐ¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²ÐºÐ°
                    field, agg_type, order = parts
                    agg_label = f"{field}_{agg_type}"
                    matching_aggregates = [agg for agg in selected_aggregates if agg.key == agg_label]
                    if matching_aggregates:
                        column = matching_aggregates[0]
                    else:
                        raise HTTPException(status_code=400, detail=f"ÐÐ³Ñ€ÐµÐ³Ð°Ñ‚ '{agg_label}' Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½")
                else:
                    raise HTTPException(status_code=400, detail=f"ÐÐµÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ñ‹Ð¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ ÑÐ¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²ÐºÐ¸: '{sort}'")

                query = query.order_by(column.desc() if order == "desc" else column.asc())

        if group_columns:
            query = query.group_by(*group_columns)

        return query
    except Exception as e:
        logging.error(f"Error in sorting or grouping: {str(e)}")
        raise HTTPException(status_code=500, detail="Internal Server Error")






